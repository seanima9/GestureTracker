{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.helper import create_and_prepare_dataset, get_data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow is using CPU\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"TensorFlow is using GPU\")\n",
    "else:\n",
    "    print(\"TensorFlow is using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler()\n",
      "1660\n",
      "515\n"
     ]
    }
   ],
   "source": [
    "PROCESSED_DATA_DIR = \"../data/processed\"\n",
    "TRAINING_DATA_DIR = \"../data/split/train\"\n",
    "VALIDATION_DATA_DIR = \"../data/split/val\"\n",
    "TEST_DATA_DIR = \"../data/split/test\"\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "print(get_data_size(TRAINING_DATA_DIR))\n",
    "print(get_data_size(VALIDATION_DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = create_and_prepare_dataset(TRAINING_DATA_DIR, BATCH_SIZE)\n",
    "validation_dataset = create_and_prepare_dataset(VALIDATION_DATA_DIR, BATCH_SIZE)\n",
    "test_dataset = create_and_prepare_dataset(TEST_DATA_DIR, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(63,)),\n",
    "        tf.keras.layers.Dense(1024, activation='relu'),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(7, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0011),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3,\n",
    "                                                        restore_best_weights=True, min_delta= 0.01)\n",
    "\n",
    "        model.fit(training_dataset.repeat(),\n",
    "                steps_per_epoch=int(5* (get_data_size(TRAINING_DATA_DIR) / BATCH_SIZE)),\n",
    "                validation_data=validation_dataset.repeat(),\n",
    "                validation_steps=int(5* (get_data_size(VALIDATION_DATA_DIR) / BATCH_SIZE)),\n",
    "                epochs=100,\n",
    "                callbacks=[early_stopping]\n",
    "        ) \n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1660/1660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.4241 - loss: 1.4248 - val_accuracy: 0.6602 - val_loss: 0.9739\n",
      "Epoch 2/100\n",
      "\u001b[1m1660/1660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6304 - loss: 0.9870 - val_accuracy: 0.7301 - val_loss: 0.8367\n",
      "Epoch 3/100\n",
      "\u001b[1m1660/1660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6924 - loss: 0.8188 - val_accuracy: 0.7398 - val_loss: 0.7106\n",
      "Epoch 4/100\n",
      "\u001b[1m1660/1660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7199 - loss: 0.7403 - val_accuracy: 0.7456 - val_loss: 0.7508\n",
      "Epoch 5/100\n",
      "\u001b[1m1660/1660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7289 - loss: 0.6938 - val_accuracy: 0.7534 - val_loss: 0.6229\n",
      "Epoch 6/100\n",
      "\u001b[1m1660/1660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7503 - loss: 0.6445 - val_accuracy: 0.8039 - val_loss: 0.5714\n",
      "Epoch 7/100\n",
      "\u001b[1m1660/1660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.7692 - loss: 0.5893 - val_accuracy: 0.7515 - val_loss: 0.7325\n",
      "Epoch 8/100\n",
      "\u001b[1m1660/1660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.7551 - loss: 0.6066 - val_accuracy: 0.8078 - val_loss: 0.5702\n",
      "Epoch 9/100\n",
      "\u001b[1m1660/1660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.7883 - loss: 0.5269 - val_accuracy: 0.8058 - val_loss: 0.5456\n",
      "Epoch 10/100\n",
      "\u001b[1m1660/1660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.7878 - loss: 0.5132 - val_accuracy: 0.8155 - val_loss: 0.5098\n",
      "Epoch 11/100\n",
      "\u001b[1m1660/1660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.8138 - loss: 0.4805 - val_accuracy: 0.8447 - val_loss: 0.4683\n",
      "Epoch 12/100\n",
      "\u001b[1m1660/1660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.8127 - loss: 0.4623 - val_accuracy: 0.7709 - val_loss: 0.6062\n",
      "Epoch 13/100\n",
      "\u001b[1m1660/1660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.8239 - loss: 0.4287 - val_accuracy: 0.8000 - val_loss: 0.6167\n",
      "Epoch 14/100\n",
      "\u001b[1m1660/1660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8325 - loss: 0.4096 - val_accuracy: 0.8427 - val_loss: 0.4838\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8575 - loss: 0.4579\n",
      "Test accuracy: 0.844660222530365\n",
      "Test loss: 0.46383604407310486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    }
   ],
   "source": [
    "model = train_model(build_model())\n",
    "\n",
    "loss, accuracy = model.evaluate(validation_dataset)\n",
    "print(f\"Test accuracy: {accuracy}\")\n",
    "print(f\"Test loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "choice = input(\"Do you want to save the model? (y/n): \")\n",
    "\n",
    "if choice.lower() == 'y':\n",
    "    model.save(f\"../models/model_acc_{accuracy:.2f}_loss_{loss:.2f}.h5\")\n",
    "    print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gesture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
